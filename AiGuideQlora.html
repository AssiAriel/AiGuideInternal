<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Guide - QloRA</title>
    <link rel="icon" href="favicon.png" type="image/png">
    <link rel="stylesheet" href="style.css"> 
</head>

<!----------------------------------------------------------------------------------------------->

<body>
    <p class="TitleHead">AI Guide - QLoRA</p>  

    <!--- Blueprint -->
    <p class="TitleList1Blue">Blueprint</p>
    <ol>
        <li>
		<!--- General QLoRA Blueprint -->
		<p class="TitleList2Blue">General QLoRA Blueprint</p>
     	<ol>
 			<li>List
            <ol>
                <li>
                Workstation: i7-14700 64GB + RTX 5070 Ti 16GB + 990PRO NVMe 2TB
				</li>
                <li>
                Model: Llama 3.1 (8B)
				</li>
                <li>
                Dataset: (yahma/alpaca-cleaned)
				</li>
                <li>
                Engine: Unsloth
				</li>
                <li>
                OS: WSL2 (Ubuntu)
				</li>
                <li>
                Code and environment file system: Linux ~/dev/AiLab
				</li>
                <li>
                Models file system: Windows DevDrive D:\ModelManagers\HuggingFace\Models\
				</li>
                <li>
                Also using :Hugging Face, bitsandbytes, triton, torch, transformers & peft
				</li>
			</ol>
 		    </li>
		</ol>
		</li>
    </ol>
 
 <!----------------------------------------------------------------------------------------------->

    <!--- Linux -->
    <p class="TitleList1Blue">Linux WSL2</p>
    <ol>
        <li>
		<!--- Install WSL -->
		<p class="TitleList2Blue">Install WSL</p>
     	<ol>
   			<li>Install
 	     	<p>Open Terminal as Administrator
            <br>type: wsl --install
            <br>when it is done restart your computer
            <br>After restart, a black window will pop up asking for a Username and Password,
            <br>(choose simple ones like: dev, dev). 
            <br>If no window pops up, open Terminal and type: wsl
            <br>if it start installing then good,
            <br>if it says "...no installed distributions" then
            <br>use 'wsl.exe --list --online' to list available distributions
            <br>type: wsl --install -d Ubuntu-24.04
            <br>If it looks like it stopped on something like "Create a default Unix user account: ssi"
            <br>then actually, it is just a print over print.
            <br>Backspace 3 times to remove the "ssi" string
            <br>and enter your user name (dev)
            <br>and then password.</p>
 		    </li>

   			<li>Uninstall
 	     	<p>If you need to uninstall, open Terminal
            <br>type: wsl --unregister Ubuntu-24.04
            <br>type: wsl --install -d Ubuntu-24.04</p>
 		    </li>
            
            <li>Check
            <ol>
                <li>
                Check that you got your user prompt on your computer
				</li>

                <li>
                Inside Ubuntu type: nvidia-smi
                <br>you should see the GPU card there
           	    <p><img src="images/FirstLinuxRun.png" alt="Numpy" width="400" style="border: 2px solid black;"></p>
                </li>
                
                <li>
                On windows Terminal, you can check that it is the right version 
           	    <p><img src="images/LinuxVer.png" alt="Numpy" width="400" style="border: 2px solid black;"></p>
				</li>
			</ol>
 		    </li>

            <li>Symbolic Link
            <ol>
                <li>
                Create a folder in WIndows D:\ModelManagers\HuggingFace\Models
				</li>

                <li>
                Move from the Windows user folder to your Linux home folder
                <br>type: cd ~
                <br>type: ln -s /mnt/d/ModelManagers/HuggingFace/Models ~/Models
                <br>To check type: cd ~/Models
                <br>type: pwd
           	    <p><img src="images/LinuxSymbolicLink.png" alt="Numpy" width="400" style="border: 2px solid black;"></p>
				</li>
			</ol>
 		    </li>

   			<li>Update Linux
 	     	<p>Type: sudo apt update && sudo apt upgrade -y</p>
 		    </li>

   			<li>Opening Ubuntu window
 	     	<p>Open Terminal and type: wsl
            <br>or, open terminal and click the little dropdown arrow at the top and select Ubuntu 24.04
            <br>or, right click the Desktop, 
            <br>New > Shortcut
            <br>location type: wsl.exe ~ -d Ubuntu-24.04
            <br>name: "AiLab Workstation"</p>
 		    </li>
		</ol>
		</li>
    </ol>

 <!----------------------------------------------------------------------------------------------->

    <!--- Miniconda -->
    <p class="TitleList1Blue">Miniconda</p>
    <ol>
        <li>
		<!--- Install Miniconda -->
		<p class="TitleList2Blue">Install Miniconda</p>
     	<ol>
   			<li>Download Installation
 	     	<p>Inside Ubuntu type: wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</p>
 		    </li>

   			<li>Install
            <p>Type: bash Miniconda3-latest-Linux-x86_64.sh
            <br>you get few "Yes" and "Enter"</p>
 		    </li>

   			<li>Activate
            <p>Type: source ~/.bashrc
            <br>and you get "(base)" in the beginning of your prompt</p>
 		    </li>

   			<li>Create a room
            <p>Type: conda create --name ailab python=3.11 -y
            <br>it might not run but give you a message that you need to accept terms,
            <br>so you need to run the two lines it gives you there.
            <br>This command creates a "room", an environment, called ailab
            <br>where specific versions of installation (like Python) reside,
            <br>note that this is not the latest Python version - but the latest stable one for Llama3.1</p>
 		    </li>

   			<li>Enter the room
            <p>Type: conda activate ailab
            <br>and you get "(ailab)" in the beginning of your prompt</p>
 		    </li>

            <li>Clean the  installation file
            <p>Type: rm Miniconda3-latest-Linux-x86_64.sh</p>
 		    </li>
		</ol>
		</li>
    </ol>

 <!----------------------------------------------------------------------------------------------->

    <!--- PyTorch -->
    <p class="TitleList1Blue">PyTorch</p>
    <ol>
        <li>
		<!--- Install PyTorch -->
		<p class="TitleList2Blue">Install PyTorch</p>
     	<ol>
   			<li>Install PyTorch
            <p>From inside your ailab room "(ailab) dev@AssiWorkstation:~$"
            <br>type: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
            <br>you get many downloads and many colors...</p>
 		    </li>
            
   			<li>Verify that Python talks to the GPU card
            <p>type: python
            <br>type: import torch
            <br>type: print(f"CUDA available: {torch.cuda.is_available()}")
            <br>type: print(f"GPU Name: {torch.cuda.get_device_name(0)}")
            <br>type: exit()
            <br>and actually, it didn't work for me, this version doesn't support sm_120 which is the CUDA architecture of my card:
           	 <p><img src="images/LinuxPytorchWarning.png" alt="Numpy" width="400" style="border: 2px solid black;"></p>
            <p>so  I need to install a newer version
            <br>from inside ailab room "(ailab) dev@AssiWorkstation:~$"
            <br>type: pip uninstall torch torchvision torchaudio -y
            <br>type: pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128
            <br>now it is better:
            <p><img src="images/LinuxPytorchInstall.png" alt="Numpy" width="400" style="border: 2px solid black;"></p>
 		    </li>

   			<li>And verify some more
            <p>Verify that (for my specific card) sm_120 is part of python
            <br>verify that  Persistence-M is On
           	 <p><img src="images/LinuxCheckSmi.png" alt="Numpy" width="400" style="border: 2px solid black;"></p>
 		    </li>
		</ol>
		</li>
    </ol>


















</body>
</html>